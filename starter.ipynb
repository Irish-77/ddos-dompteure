{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "174904be-8186-40c0-a26d-dda1b8c8a248",
   "metadata": {},
   "source": [
    "# Starter\n",
    "This notebook is intended to provide you an easy use of the repository. It is tested on windows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38159b4c-39d2-4fdf-9df2-e781ddc380ce",
   "metadata": {},
   "source": [
    "---\n",
    "## Check Python Version\n",
    "Due to some issues in former versions, we recommend to use Python Version 3.9.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe35e58-2e0c-423b-aecd-4ecb067906fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0ded95-9d86-409b-8f15-9a7af6718e52",
   "metadata": {},
   "source": [
    "---\n",
    "## Install Requirements\n",
    "Install the required packages to use the other functions and methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c0727b-55d4-4d20-90f3-f2a2281980d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497bc4ba-2332-4760-b296-3536f961ced2",
   "metadata": {},
   "source": [
    "---\n",
    "## Load necessary packages for this Guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c173bd67-e626-4fe6-9847-cea1defe6bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31708de8-e3d8-4cff-b622-04cd508ba07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "from pathlib import Path\n",
    "from joblib import load\n",
    "import dask.dataframe as dd\n",
    "from scripts.dataset_all_prep import pipeline\n",
    "from scripts.classifier import Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f215b8ab-e5d5-465a-aef5-9b418a62cf56",
   "metadata": {},
   "source": [
    "---\n",
    "## Get Dataset and Prepare it\n",
    "**This step is only necessary if you do not want to use the pre-trained models or the use cases.**\n",
    "\n",
    "Since the dataset is to large for version control, you can download it using [here](https://www.kaggle.com/devendra416/ddos-datasets?select=ddos_imbalanced). Make sure to download the unbalanced dataset. Place the file inside the root folder of this repo and name if 'unbalaced_20_80_dataset.csv' if it is not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb60d94f-98cc-4a8f-8a36-8321624b7720",
   "metadata": {},
   "source": [
    "Check if the dataset is correctly inserted. The output of the following cell should be 'True'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71fcae5c-be5b-4fe3-8ad5-71c4ceee6251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path.isfile('unbalaced_20_80_dataset.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47c3da3-b1a1-4bd3-b118-b9b05d5d8377",
   "metadata": {},
   "source": [
    "Load the dataset into an Dask-DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40f7538-5dcf-4988-b688-73445532a026",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dd.read_csv('unbalaced_20_80_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42328e8c-331a-43b1-a8c0-f131166514fc",
   "metadata": {},
   "source": [
    "In this step, the data is cleaned and prepared using a pre-built pipeline. If you want to got through each step, use the files data_cleaning.ipynb, data_exploration.ipynb and data_preparation.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7642ff17-ceeb-4584-863d-75434655d6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline(df, output_file=Path('./prepared_ds.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdeb1ec2-ac66-4264-924b-e265d4f5dd3b",
   "metadata": {},
   "source": [
    "Check if the pipeline generated the required file. The output of the following cell should be 'True'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5183a8d-bd24-4e6c-b37e-025155dee9f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path.isfile('prepared_ds.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c950b30-faad-463f-bd5d-45fa98a5dc65",
   "metadata": {},
   "source": [
    "---\n",
    "## Create Models\n",
    "**This step is only necessary if you do not want to use the pre-trained models.**\n",
    "\n",
    "To train the models by yourself, use either file starting with 'model_'. However, some files may take up to several hours depending on the system. For further instructions on how to use the models, please see [sklearn documentation](https://scikit-learn.org/stable/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994e8ba7-b1e4-407b-9f70-c39265410ac9",
   "metadata": {},
   "source": [
    "---\n",
    "## Use (pre-built) Models\n",
    "To use models which are already built, load any model of the models folder with the file ending '.model' or '.joblib'. For further instructions on how to use the models, please see [sklearn documentation](https://scikit-learn.org/stable/). Please note, that we could not upload all models due to storage limitations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e78842c-b78d-464c-80b7-6a58697504fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = load('models/RandomForestClassifier_AdaBoost2.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18797418-ba61-4926-9ea2-6d3c3ba87046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=10, verbose=1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.base_estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589e4c39-8dc7-4b67-a3f8-856003a73522",
   "metadata": {},
   "source": [
    "---\n",
    "## Example Use Case 1: Classifier\n",
    "This is an example use case of the models. The classifier is a custom built class which utilizes the models to predict the classification of a network communication entry.\n",
    "\n",
    "First, we need to initialize a new object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94c042f6-96de-44ea-a91b-19e25a9e9d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe81c9c4-0fc9-49e0-b31b-696aafb58ece",
   "metadata": {},
   "source": [
    "We can change the model to predict the values using the method shown below. Currently, the following models are available:\n",
    "  - 'RFC': RandomForestClassifier.joblib, Default on initialization\n",
    "  - 'NN': neural_network_prod.model \n",
    "  - 'RFC_Ada': RandomForestClassifier_AdaBoost.joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb095b75-634f-42e3-baf3-4f027ca3aec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.set_current_model('RFC_Ada')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbbb8ae-8962-4c75-8a2d-49b87dfc7ad1",
   "metadata": {},
   "source": [
    "To test the model, we create a new dataset which consists of about 0.1% of the whole dataset. First, check if the necessary file is available. The output of the first cell should be 'True'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06692c9b-2a96-4567-ad2d-8344e2149617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path.isfile('unbalaced_20_80_dataset.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28b420d1-9b3b-4db6-91c6-e8b156c1d4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = dd.read_csv('unbalaced_20_80_dataset.csv').sample(frac=0.001, random_state = 4).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefb5f30-a99d-4e24-a5e9-bcbfcf53b5da",
   "metadata": {},
   "source": [
    "Predict the values of the test dataset and show the according ips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de87bdb3-239d-4f79-889e-f2c720b222bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, ips = c.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66fcfa77-def6-45ac-aea7-c511874de719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ddos' 'ddos' 'ddos' ... 'Benign' 'Benign' 'Benign']\n",
      "                 Src IP\n",
      "72997     18.219.193.20\n",
      "119451     172.31.69.25\n",
      "51578     18.219.193.20\n",
      "59757      172.31.69.28\n",
      "97909    18.216.200.189\n",
      "...                 ...\n",
      "21456      172.31.64.86\n",
      "24966      79.175.45.92\n",
      "18724   145.239.183.169\n",
      "5823       172.31.67.80\n",
      "15845           8.6.0.1\n",
      "\n",
      "[7567 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)\n",
    "print(ips)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6568bcc9-505b-435e-88fc-129806156765",
   "metadata": {},
   "source": [
    "Test if a specific ip address is predicted as 'ddos'. The output is 'False' if the ip is either classified as 'benign' or unknown to the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20f49bb4-6ab9-4bf9-8018-1cac0eda196e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.is_malicious('18.219.193.20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a7e465d-9de7-46e9-9596-1c8bdb4c07af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.is_malicious('8.6.0.1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e41cf0-a6ce-4ac5-991f-f59323207fe5",
   "metadata": {},
   "source": [
    "---\n",
    "## Example Use Case 2: API\n",
    "This use case utilizes the models inside of an api. The api is inteded to be used by different firewall providers. The firewalls of these providers can send their aggregated network communication to the api and receive a classification of the request based on which the firewall can exclude the ip address from further communication. Moreover, black- and whitelisted ips can be requested. Using the `/ip/{ip}/status` endpoint, the firewall receives a classification based on the classification of the last 10 entries for a specific ip.\n",
    "\n",
    "The classification inside this system encompasses a voting system. The voting system consists of mutliple of our trained models which classify each entry. In this specifc case, two of our best models are used. To prevent the models from predicting contrary values (e.g. 1 ddos, 1 benign), the `predict_proba` function of the *sklearn* library is used. The mean of all predicted values for a record is used to return the classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928dea2f-4e52-4bdf-84ad-62203be50a46",
   "metadata": {},
   "source": [
    "### Installation and Use\n",
    "\n",
    "To install the docker images and build the container, open a cmd prompt inside the service folder. Type `docker compose up` inside the prompt. All required images will be installed and the container built up. The process might take a few minutes. The first installation will take longer since dummy data is inserted into the database.\n",
    "\n",
    "The api can be accessed using `localhost:5000/v1` inside the browser. An example user is already implemented:\n",
    "- email: herbert@gmail.com\n",
    "- password: Passwort123!\n",
    "After a login, copy the authorization header looking similar to this: \n",
    ">`Bearer eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJleHAiOjE2MjUxNjY2MTYsImlhdCI6MTYyNTA4MDIxNiwic3ViIjoiaGVyYmVydEBnbWFpbC5jb20ifQ.n5UNLWJzdvVToTANstRMJwVo5Up4GEgi8XhxXVEFbd8` \n",
    "\n",
    "and insert it inside the authorization field of the endpoints. You can try this using the `/user/company` endpoint. The request should return `{\"company\": \"Apple\"}`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e71f3a5-c48d-40f4-a3e4-94462880de30",
   "metadata": {},
   "source": [
    "### API Description\n",
    "\n",
    "#### users\n",
    "\n",
    "| Endpoint                       | Method     | Description                                   |\n",
    "| ------------------------------ | ---------- | --------------------------------------------- |\n",
    "| /user/company                  | get        | get company of user by token (jwt)            |\n",
    "| /user/signin                   | post       | signin with user credentials                  |\n",
    "| /user/signup                   | post       | create new user                               |\n",
    "| /user/update                   | post       | update names of a user                        |\n",
    "| /user/update                   | get        | get updatable fields of an user               |\n",
    "| /user/verify-token             | post       | verify that the token is valid                |\n",
    "\n",
    "#### companies\n",
    "\n",
    "| Endpoint                       | Method     | Description                                   |\n",
    "| ------------------------------ | ---------- | --------------------------------------------- |\n",
    "| /company/list                  | get        | get list of all registered companies          |\n",
    "| /company/register              | post       | register a new company<sup>1</sup>            |\n",
    "| /company/{company}             | get        | get all users of a company                    |\n",
    "\n",
    "<sup>1</sup>This endpoint is only for illustrative purposes. In a real environment we do not recommend to have an unprotected endpoint for creating a company.\n",
    "\n",
    "#### ips\n",
    "\n",
    "| Endpoint                       | Method     | Description                                   |\n",
    "| ------------------------------ | ---------- | --------------------------------------------- |\n",
    "| /ip/                           | post       | post new record, returns classification       |\n",
    "| /ip/blacklist                  | get        | list of possible harmful ip addresses         |\n",
    "| /ip/whitelist                  | get        | list of possible harmless ip addresses        |\n",
    "| /ip/{ip}                       | get        | get class counts of last 10 entries of ip     |\n",
    "| /ip/{ip}/status                | get        | get current status of ip                      |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
