{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d9b307e-53bc-4418-a2d1-55c13ca0a147",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6eb3b35-a59a-4565-8d66-4f4c8b294c4f",
   "metadata": {},
   "source": [
    "## Import and Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4455ad06-cd84-4334-9ad9-63ec0d9c2db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be86842c-949a-4bc0-b0e3-6e09ebc69daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef23f69a-d9ca-41c4-9841-b593913ca5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d844b7c-3a73-4274-9900-6ba4d0f15209",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import dask.dataframe as dd\n",
    "import dask.array as da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f13584e6-9b51-40fe-aba2-6ef196eb29b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from joblib import dump, load\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, AdaBoostClassifier, BaggingClassifier, VotingClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4f9dcb9-cd13-491a-9757-114980000e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dd.read_csv('prepared_ds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "36b6be0c-575f-445b-8ed7-30bb467a1b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "class Classifier:\n",
    "\n",
    "    current_ml_model = None\n",
    "    models = {\n",
    "        'NN': 'models/path',\n",
    "        'kNN': 'models/path',\n",
    "        'RFC_Ada': 'models/RandomForestClassifier_AdaBoost.joblib',\n",
    "        'RFC': 'models/RandomForestClassifier.joblib'\n",
    "    }\n",
    "    \n",
    "    blacklist = 'models/blacklist.txt'\n",
    "    blacklist = 'models/blacklist.txt'\n",
    "\n",
    "    def __init__(self, model_name='RFC'):\n",
    "        self.set_current_model(model_name)\n",
    "        \n",
    "    def set_current_model(self, model_name):\n",
    "        self.current_ml_model = self.load_obj(self.models[model_name])\n",
    "    \n",
    "    def read_model(self, filename):\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X, blacklist = True, whitelist = True):\n",
    "        X_transformed = self.pipeline(X)\n",
    "        \n",
    "        predictions = self.current_ml_model.predict(X_transformed)\n",
    "        \n",
    "        ddos = df[[]]\n",
    "        \n",
    "        return \n",
    "    \n",
    "    def load_obj(self, filename):\n",
    "        return load(filename)\n",
    "    \n",
    "    def encode_ports(self, x):\n",
    "        if x < 1024:\n",
    "             y= 'System'\n",
    "        elif x > 1023 and x < 49152:\n",
    "             y= 'User'\n",
    "        else :\n",
    "             y= 'Dynamic' \n",
    "        return y\n",
    "    \n",
    "    def is_malicious(self, ip):\n",
    "        pass\n",
    "    \n",
    "    def is_benign(self, ip):\n",
    "        pass\n",
    "        \n",
    "    \n",
    "    def pipeline(self, df):\n",
    "        \n",
    "        try:\n",
    "            df = df.drop([\"Unnamed: 0\"], axis=1)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Stage 1 - Cleaning\n",
    "        df_cleaned = df[~df['Flow Byts/s'].isin([np.inf, -np.inf])]\n",
    "        df_cleaned = df_cleaned.dropna(subset=['Flow Byts/s'])\n",
    "        df_cleaned = df_cleaned.drop(['Fwd URG Flags', 'Bwd URG Flags', 'Fwd Byts/b Avg', 'Fwd Pkts/b Avg', 'Bwd Byts/b Avg', 'Bwd Pkts/b Avg', 'Fwd Blk Rate Avg', 'Bwd Blk Rate Avg'], axis=1)\n",
    "        \n",
    "        # Stage 2 - Exploring\n",
    "        df_cleaned['dst_port_transformed'] = df_cleaned['Dst Port'].apply(self.encode_ports)\n",
    "        df_cleaned['src_port_transformed'] = df_cleaned['Src Port'].apply(self.encode_ports)\n",
    "        to_be_removed = ['Fwd PSH Flags', 'Bwd PSH Flags', 'FIN Flag Cnt', 'URG Flag Cnt', 'Src Port', 'Dst Port', 'Flow ID', 'Timestamp']\n",
    "        df_explored = df_cleaned.drop(to_be_removed, axis=1)        \n",
    "        \n",
    "        # Stage 3 - Preperation\n",
    "        scaler = self.load_obj('models/std_scaler.joblib')\n",
    "        pca = self.load_obj('models/pca.joblib')\n",
    "        encoder = self.load_obj('models/one_hot_encoder.transformer')\n",
    "        \n",
    "        \n",
    "        category_vars = ['Protocol','SYN Flag Cnt', 'RST Flag Cnt', 'PSH Flag Cnt', 'ACK Flag Cnt', 'CWE Flag Count', 'ECE Flag Cnt', 'dst_port_transformed', 'src_port_transformed']\n",
    "        object_vars = ['Dst IP', 'Src IP']\n",
    "        continuous_vars = df_explored.columns[~df_explored.columns.isin(category_vars) & ~df_explored.columns.isin(object_vars)]\n",
    "        \n",
    "        \n",
    "        X = scaler.transform(df_explored[continuous_vars].values)\n",
    "        principal_components = pca.transform(X)\n",
    "        col_names = [f'PC-{i}' for i in range(principal_components.shape[1])]\n",
    "        df_pca = pd.DataFrame(data = principal_components, columns = col_names)\n",
    "        \n",
    "        to_be_encoded = [\"Protocol\", \"dst_port_transformed\", \"src_port_transformed\"]\n",
    "        df_encoded = pd.DataFrame(encoder.transform(df_explored[to_be_encoded]))\n",
    "        df_encoded.columns = encoder.get_feature_names(to_be_encoded)\n",
    "        \n",
    "        to_be_not_encoded = [i for i in category_vars if i not in to_be_encoded]\n",
    "        \n",
    "        max_pca = 24\n",
    "        df_categories = pd.concat([df_encoded, df_explored[to_be_not_encoded].reset_index()[to_be_not_encoded]], axis = 1)\n",
    "        df_prepared = pd.concat([df_categories, df_pca.iloc[:,list(range(max_pca))]], axis = 1)\n",
    "   \n",
    "        return df_prepared\n",
    "    \n",
    "    def save_obj(self, obj, file):\n",
    "        pass\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1aa92075-75e6-409e-943f-ed9a084c6c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import dask.dataframe as dd\n",
    "import dask.array as da\n",
    "df = dd.read_csv('unbalaced_20_80_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ffec92-fe64-4b35-80f1-c1369ec607b0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test = df.sample(frac=0.001, random_state = 4).compute()\n",
    "labels = df_test[\"Label\"]\n",
    "df_X = df_test.drop([\"Label\", \"Unnamed: 0\"], axis=1)\n",
    "df_ddos_X = df_ddos.drop([\"Label\", \"Unnamed: 0\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cfdd29d0-6129-480d-b9a9-5140e45e3b7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ddos', 'ddos', 'ddos', ..., 'Benign', 'Benign', 'Benign'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = Classifier()\n",
    "df_result = c.pipeline(df_X)\n",
    "predictions = c.predict(df_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "92f90fe8-3c02-4b6b-aef2-89495a3e1042",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ddos = df_test.loc[df_test['Label'] == 'ddos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "67c8738c-6a56-4b80-84cf-50d99c217f5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7567, (7608,))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions), labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "47da9abe-578c-4334-bb3a-5afef3e7da28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e871f771-b883-4de0-b101-5d73f10f8393",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df_test.iterrows():\n",
    "    if row[\"Label\"] = \"Benign\":\n",
    "        continue\n",
    "     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
